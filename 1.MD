# Description
A statistical techniques aimed at visualizing the similarity or dissimilarity ,model data as distance in a geometric space, often for visuulization in 2 ot 3 dimensions.

# Procedure
Begin with a matrix of dissimilarities between pairs of items. MDS find a set of vectors in a low-dimensional that approxiates these dissimilarities.

# Strength
Provide intuitive geometric representations of complex relationships amaong items, making it easier to identity patterns, clusters, or outliers within the data

# Limitation
It's sensitive to choice of dissimilarity and initial configuration. 
Hard to interpret.

# R command 
sim2diss(data, type = '') argument type dependent on the original data

cmdsacle(euromat, k = 2) #for distance

mds(crime.dist,ndim=2,type="interval") # for corr,rank, probability....
type = interval  # for metric, the diffrernce between data are meaningful, can be analiesd directly.
type = ordinal #just ordinal





# Decision tree
## Description:
a classification tree is a step-by-step guide that helps us decide which category something belongs to. It asks yes/no questions until it reaches a decision

## Procedure :
1.start with all data
2.ask a question
3.kepp splitting
4.decision

## Advatange :
 Simple and interpretable modles, can handle categorical and numerical data

## Limitation:
Prone to overfitting,experically with coplex data or without proper pruning


## Description 
Bagging involves creating multiple decision trees using different chunks of the data and then letting all the the trees vote on the final deciosn

## Procedure
1.bootsstrap to make many groups, 
2.buiid trees, for each small box build a decision tree
3. vote on the decision, make each tree to make decision, the most common decision wins.

## Strength : 
Reduce the variance, make it more robust to the a singe decision tree

## Limitation :
 increase the model complexity reduce the intepretability to a single decision tree. The performance is heavily dependent on the strength of the single tree

## Description
Random forest imporve on bagging by making each tree in the forest at different questions.
1. make many tress,just like bagging trees.
2. diverse question. for each tree ,only use a few random questions from a list of possible questions.
3. vote for the best(most common)

## Strength
More effecitive at reducing variance than bagging trees, the most powerful out- of - the - box classfier.

## Limitation
Incerase the model complexity ,reduce the intepretability 
